{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/media/vanilla/Fun/zhongxing/Test/\"\n",
    "model = \"/media/vanilla/Fun/zhongxing/banben/TestModel.caffemodel\"\n",
    "prototxt = \"/media/vanilla/Fun/zhongxing/banben/TestModel.prototxt\"\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Net(prototxt, model, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pruner(object):\n",
    "    def __init__(self, net):\n",
    "        self._net = net\n",
    "        self.conv_data = {}\n",
    "        self.candi  = ['conv3_1_1b','conv4_1_1b','conv5_1_1b']\n",
    "        \n",
    "    def _prune_res(self, conv_param, del_kernels=None, not_del_filters=False, ind=0):\n",
    "        weight, bias = conv_param\n",
    "        weight = weight.data\n",
    "        bias = bias.data\n",
    "        origin_channels = weight.shape[0]\n",
    "        mask = self.candi[ind]\n",
    "        print('weight start:',weight.shape)\n",
    "#         print(del_kernels)\n",
    "        cnt = 0\n",
    "        del_filters = []\n",
    "        maxx = self.conv_data[mask][0].shape[0]\n",
    "#         print(self.conv_data[mask][0].shape,origin_channels,maxx)\n",
    "#         print(self.conv_data[mask][0].shape)\n",
    "        \n",
    "        # delete filters\n",
    "        if not not_del_filters:\n",
    "            abs_mean = np.abs(weight).mean(axis=(1,2,3))\n",
    "            for index,v in enumerate(abs_mean):\n",
    "#                 if v < 5e-1 and cnt < origin_channels-maxx:\n",
    "#                     del_filters.append(index)\n",
    "#                     cnt += 1\n",
    "#                     print(cnt)\n",
    "#                 abs_mean = np.abs(weight).mean(axis=(1,2,3))\n",
    "#                 a = sorted(list(abs_mean))\n",
    "#                 print(list(abs_mean).index(a[:origin_channels-maxx]))\n",
    "                del_filters = np.where(abs_mean < 1e-22)[0]\n",
    "                del_filters = del_filters[:origin_channels-maxx]\n",
    "            print(del_filters)\n",
    "            weight = np.delete(weight, del_filters, axis=0)\n",
    "#             print(weight.shape)\n",
    "            bias = np.delete(bias, del_filters, axis=0)\n",
    "        else:\n",
    "            del_filters = np.array([])\n",
    "        \n",
    "        # delete kernels\n",
    "        if del_kernels is not None:\n",
    "            weight = np.delete(weight, del_kernels, axis=1)\n",
    "            print(weight.shape)\n",
    "#         else:\n",
    "#             abs_mean = np.abs(weight).mean(axis=(1,2,3))\n",
    "#             for index,v in enumerate(abs_mean):\n",
    "#     #                 if v < 5e-1 and cnt < origin_channels-maxx:\n",
    "#     #                     del_filters.append(index)\n",
    "#     #                     cnt += 1\n",
    "#     #                     print(cnt)\n",
    "#     #             abs_mean = np.abs(weight).mean(axis=(1,2,3))\n",
    "#     #             a = sorted(list(abs_mean))\n",
    "#     #                 print(list(abs_mean).index(a[:origin_channels-maxx]))\n",
    "#                 del_filters = np.where(abs_mean < 1e-22)[0]\n",
    "#                 del_filters = del_filters[:origin_channels-maxx]\n",
    "#             weight = np.delete(weight, del_filters, axis=1)\n",
    "    #             print(weight.shape)\n",
    "    #         bias = np.delete(bias, del_filters, axis=1)\n",
    "\n",
    "\n",
    "            \n",
    "        print('weight final:',weight.shape)\n",
    "            \n",
    "        return weight, bias, del_filters, origin_channels\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _prune(self, conv_param, del_kernels=None, not_del_filters=False, layer='conv'):\n",
    "        weight, bias = conv_param\n",
    "        weight = weight.data\n",
    "        bias = bias.data\n",
    "        origin_channels = weight.shape[0]\n",
    "#         print(\"del_kernels:\",del_kernels)\n",
    "        print('weight start:',weight.shape)\n",
    "        \n",
    "        # delete filters\n",
    "        if not not_del_filters:\n",
    "            abs_mean = np.abs(weight).mean(axis=(1,2,3))\n",
    "            del_filters = np.where(abs_mean < 1e-32)[0]\n",
    "            print(type(del_filters), len(del_filters))\n",
    "            print(min(abs_mean))\n",
    "            weight = np.delete(weight, del_filters, axis=0)\n",
    "            bias = np.delete(bias, del_filters, axis=0)\n",
    "        else:\n",
    "            del_filters = np.array([])\n",
    "        \n",
    "        # delete kernels\n",
    "        if del_kernels is not None:\n",
    "            if layer == \"conv\":\n",
    "#                 print(weight)\n",
    "                weight = np.delete(weight, del_kernels, axis=1)\n",
    "#                 print(weight.shape)\n",
    "            else:\n",
    "                weight = np.reshape(weight,(160,1536,9,9))\n",
    "                weight = np.delete(weight, del_kernels, axis=1)\n",
    "#                 print(weight.shape)\n",
    "                weight = np.reshape(weight, (160,-1))\n",
    "        print('weight final:',weight.shape)\n",
    "            \n",
    "        return weight, bias, del_filters, origin_channels\n",
    "    \n",
    "    def prune_conv(self, name, bottom=None):\n",
    "        if bottom is None:\n",
    "            self.conv_data[name] = self._prune(self._net.params[name])\n",
    "        else:\n",
    "            self.conv_data[name] = self._prune(self._net.params[name], self.conv_data[bottom][2])\n",
    "            \n",
    "    def prune_resual(self, name, bottom=None, ind=0,not_del_filters=True):\n",
    "        if bottom is None:\n",
    "            self.conv_data[name] = self._prune_res(self._net.params[name],ind=ind,not_del_filters=not_del_filters)\n",
    "        else:\n",
    "            self.conv_data[name] = self._prune_res(self._net.params[name], self.conv_data[bottom][2],not_del_filters=False,ind=ind)\n",
    "            \n",
    "    def prune_concat(self, name, bottoms,layer=\"conv\"):\n",
    "        if layer == 'conv':\n",
    "            offsets = [0] + [self.conv_data[b][3] for b in bottoms]\n",
    "#             print(offsets)\n",
    "            for i in range(1, len(offsets)):\n",
    "                offsets[i] += offsets[i-1]\n",
    "#             print(offsets)\n",
    "    #         for v in bottoms:\n",
    "    #             print(self.conv_data[v][2])\n",
    "            del_filters = [self.conv_data[b][2] + offsets[i] for i, b in enumerate(bottoms)]\n",
    "#             print(del_filters)\n",
    "            del_filters_new = np.concatenate(del_filters)\n",
    "            a = self._net.params[name][0].data.shape\n",
    "#             print(\"hahaha:\",del_filters_new,a)\n",
    "            if name == 'conv5_1_1b':\n",
    "                self.conv_data[name] = self._prune(self._net.params[name], del_filters_new, not_del_filters=False)\n",
    "            else:\n",
    "                self.conv_data[name] = self._prune(self._net.params[name], del_filters_new, not_del_filters=True)\n",
    "        else:\n",
    "            offsets = [0] + [self.conv_data[b][3] for b in bottoms]\n",
    "#             print(offsets)\n",
    "            for i in range(1, len(offsets)):\n",
    "                offsets[i] += offsets[i-1]\n",
    "            print(offsets)\n",
    "    #         for v in bottoms:\n",
    "    #             print(self.conv_data[v][2])\n",
    "            del_filters = [self.conv_data[b][2] + offsets[i] for i, b in enumerate(bottoms)]\n",
    "#             print(del_filters)\n",
    "            del_filters_new = np.concatenate(del_filters)\n",
    "            a = self._net.params[name][0].data.shape\n",
    "#             print(\"hahaha:\",del_filters_new,a)\n",
    "            if name == 'conv5_1_1b':\n",
    "                self.conv_data[name] = self._prune(self._net.params[name], del_filters_new, not_del_filters=True)\n",
    "            else:\n",
    "                self.conv_data[name] = self._prune(self._net.params[name], del_filters, not_del_filters=True, layer='fc')\n",
    "    \n",
    "    def prune_sum(self, name, bottoms,layer=\"conv\"):\n",
    "        out = 0\n",
    "        del_filters = []\n",
    "        weight, bias = self._net.params[name]\n",
    "        weight = weight.data\n",
    "        bias = bias.data\n",
    "        origin_channels = weight.shape[0]\n",
    "        print('weight start :', weight.shape)\n",
    "        cha = self.conv_data[bottoms[0]][0].shape[1]\n",
    "        for i in bottoms:\n",
    "            out += self.conv_data[i][0][:,:cha,:,:]\n",
    "        weight = out\n",
    "        print('weight finally :', weight.shape)\n",
    "        self.conv_data[name] = (weight, bias, del_filters, origin_channels)\n",
    "    \n",
    "    def prune_concat_fc(self, name, bottoms,layer=\"conv\"):\n",
    "        out = 0\n",
    "        cnt = 0\n",
    "        del_filters = [ ]\n",
    "        weight, bias = self._net.params[name]\n",
    "        weight = weight.data\n",
    "        bias = bias.data\n",
    "        origin_channels = weight.shape[0]\n",
    "        print('weight start :', weight.shape)\n",
    "        cha = self.conv_data[bottoms[0]][0].shape[1]\n",
    "        origin_channels = 512\n",
    "        for i in bottoms:\n",
    "            if cnt == 2:\n",
    "                break\n",
    "            out += self.conv_data[i][0][:,:cha,:,:]\n",
    "            cnt += 1\n",
    "        self.conv_data['mask'] = (out, bias, del_filters, origin_channels)   \n",
    "        bottoms.remove(\"conv5_6_2\")\n",
    "        bottoms.remove(\"conv5_6_1\")\n",
    "        bottoms.append(\"mask\")\n",
    "        offsets = [0] + [self.conv_data[b][3] for b in bottoms]\n",
    "#             print(offsets)\n",
    "        for i in range(1, len(offsets)):\n",
    "            offsets[i] += offsets[i-1]\n",
    "        print(offsets)\n",
    "        for v in bottoms:\n",
    "            print(self.conv_data[v][2])\n",
    "        del_filters = [np.asarray(self.conv_data[b][2]) + offsets[i] for i, b in enumerate(bottoms)]\n",
    "        print(del_filters)\n",
    "        del_filters_new = np.concatenate(del_filters)\n",
    "        print(del_filters_new)\n",
    "#         a = self._net.params[name][0].data.shape\n",
    "#             print(\"hahaha:\",del_filters_new,a)\n",
    "        if name == 'conv5_1_1b':\n",
    "            self.conv_data[name] = self._prune(self._net.params[name], del_filters_new, not_del_filters=True)\n",
    "        else:\n",
    "            self.conv_data[name] = self._prune(self._net.params[name], del_filters_new, not_del_filters=True, layer='fc')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#         weight = np.reshape(weight,(160,1536,9,9))\n",
    "#         weight = np.delete(weight, del_kernels, axis=1)\n",
    "#         #                 print(weight.shape)\n",
    "#         weight = np.reshape(weight, (160,-1))\n",
    "#         weight = out\n",
    "#         print('weight finally :', weight.shape)\n",
    "#         self.conv_data[name] = (weight, bias, del_filters, origin_channels)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def save(self, new_model, output_weights):\n",
    "        net2 = caffe.Net(new_model, caffe.TEST)\n",
    "#         print(self.conv_data.keys())\n",
    "        for key in net2.params.keys():\n",
    "            print(key)\n",
    "            if key in self.conv_data:\n",
    "                print(self.conv_data[key][0].shape)\n",
    "                net2.params[key][0].data[...] = self.conv_data[key][0]\n",
    "                net2.params[key][1].data[...] = self.conv_data[key][1]\n",
    "            else:\n",
    "#                 print(self.conv_data[key][0].shape,net2.params[key][0].shape)\n",
    "                net2.params[key][0].data[...] = net.params[key][0].data\n",
    "                net2.params[key][1].data[...] = net.params[key][1].data\n",
    "        net2.save(output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = Pruner(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight start: (32, 3, 3, 3)\n",
      "<class 'numpy.ndarray'> 1\n",
      "7.071002e-33\n",
      "weight final: (31, 3, 3, 3)\n",
      "weight start: (32, 3, 3, 3)\n",
      "<class 'numpy.ndarray'> 3\n",
      "5.3326602e-33\n",
      "weight final: (29, 3, 3, 3)\n",
      "weight start: (32, 32, 3, 3)\n",
      "<class 'numpy.ndarray'> 1\n",
      "7.738279e-33\n",
      "weight final: (31, 29, 3, 3)\n",
      "weight start: (32, 3, 3, 3)\n",
      "<class 'numpy.ndarray'> 2\n",
      "5.7964817e-33\n",
      "weight final: (30, 3, 3, 3)\n",
      "weight start: (32, 32, 3, 3)\n",
      "<class 'numpy.ndarray'> 4\n",
      "2.5248304e-33\n",
      "weight final: (28, 30, 3, 3)\n",
      "weight start: (32, 32, 3, 3)\n",
      "<class 'numpy.ndarray'> 5\n",
      "7.3803137e-34\n",
      "weight final: (27, 28, 3, 3)\n",
      "weight start: (64, 96, 3, 3)\n",
      "weight final: (64, 89, 3, 3)\n",
      "weight start: (64, 64, 3, 3)\n",
      "<class 'numpy.ndarray'> 0\n",
      "0.004236547\n",
      "weight final: (64, 64, 3, 3)\n",
      "weight start: (64, 64, 3, 3)\n",
      "<class 'numpy.ndarray'> 1\n",
      "3.7985343e-33\n",
      "weight final: (63, 64, 3, 3)\n",
      "weight start: (64, 64, 3, 3)\n",
      "<class 'numpy.ndarray'> 0\n",
      "0.01365149\n",
      "weight final: (64, 63, 3, 3)\n",
      "weight start: (64, 64, 3, 3)\n",
      "<class 'numpy.ndarray'> 0\n",
      "0.019319572\n",
      "weight final: (64, 64, 3, 3)\n",
      "weight start: (64, 64, 3, 3)\n",
      "<class 'numpy.ndarray'> 2\n",
      "8.8011255e-34\n",
      "weight final: (62, 64, 3, 3)\n",
      "weight start: (64, 64, 3, 3)\n",
      "<class 'numpy.ndarray'> 0\n",
      "3.1931754e-32\n",
      "weight final: (64, 62, 3, 3)\n",
      "weight start: (64, 64, 3, 3)\n",
      "<class 'numpy.ndarray'> 2\n",
      "3.2051114e-34\n",
      "weight final: (62, 64, 3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanilla/.conda/envs/testcaffe/lib/python3.5/site-packages/ipykernel_launcher.py:92: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pruner.prune_conv(\"conv1_1_1\")\n",
    "pruner.prune_conv(\"conv1_2_1\")\n",
    "pruner.prune_conv(\"conv1_2_2\", \"conv1_2_1\")\n",
    "pruner.prune_conv(\"conv1_3_1\")\n",
    "pruner.prune_conv(\"conv1_3_2\", \"conv1_3_1\")\n",
    "pruner.prune_conv(\"conv1_3_3\", \"conv1_3_2\")\n",
    "pruner.prune_concat(\"conv2_1\", (\"conv1_1_1\", \"conv1_2_2\", \"conv1_3_3\"))\n",
    "pruner.prune_conv(\"conv2_2\", \"conv2_1\")\n",
    "pruner.prune_conv(\"conv2_3\", \"conv2_2\")\n",
    "pruner.prune_conv(\"conv2_4\", \"conv2_3\")\n",
    "pruner.prune_conv(\"conv2_5\", \"conv2_4\")\n",
    "pruner.prune_conv(\"conv2_6\", \"conv2_5\")\n",
    "pruner.prune_conv(\"conv2_7\", \"conv2_6\")\n",
    "pruner.prune_conv(\"conv2_8\", \"conv2_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight start: (128, 256, 3, 3)\n",
      "weight final: (128, 252, 3, 3)\n",
      "weight start: (128, 256, 1, 1)\n",
      "weight final: (128, 252, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "pruner.prune_concat(\"conv3_1_1\", (\"conv2_2\", \"conv2_4\", \"conv2_6\", \"conv2_8\"))\n",
    "pruner.prune_concat(\"conv3_1_1b\", (\"conv2_2\", \"conv2_4\", \"conv2_6\", \"conv2_8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (128, 128, 3, 3)\n",
      "[]\n",
      "(128, 128, 3, 3)\n",
      "weight final: (128, 128, 3, 3)\n",
      "weight start: (256, 384, 3, 3)\n",
      "weight final: (256, 384, 3, 3)\n",
      "weight start: (256, 384, 1, 1)\n",
      "weight final: (256, 384, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanilla/.conda/envs/testcaffe/lib/python3.5/site-packages/ipykernel_launcher.py:43: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "pruner.prune_resual(\"conv3_1_2\", \"conv3_1_1\",ind=0)\n",
    "pruner.prune_resual(\"conv3_2_1\",\"conv3_1_1b\",ind=0)\n",
    "pruner.prune_resual(\"conv3_2_2\", \"conv3_2_1\",ind=0)\n",
    "pruner.prune_resual(\"conv3_3_1\",\"conv3_1_1b\",ind=0)\n",
    "pruner.prune_resual(\"conv3_3_2\", \"conv3_3_1\",ind=0)\n",
    "pruner.prune_resual(\"conv3_4_1\",\"conv3_1_1b\",ind=0)\n",
    "pruner.prune_resual(\"conv3_4_2\", \"conv3_4_1\",ind=0)\n",
    "pruner.prune_resual(\"conv3_5_1\",\"conv3_1_1b\",ind=0)\n",
    "pruner.prune_resual(\"conv3_5_2\", \"conv3_5_1\",ind=0)\n",
    "pruner.prune_resual(\"conv3_6_1\",\"conv3_1_1b\",ind=0)\n",
    "pruner.prune_resual(\"conv3_6_2\", \"conv3_6_1\",ind=0)\n",
    "pruner.prune_concat(\"conv4_1_1\", (\"conv3_2_2\", \"conv3_4_2\", \"conv3_6_2\"))\n",
    "pruner.prune_concat(\"conv4_1_1b\", (\"conv3_2_2\", \"conv3_4_2\", \"conv3_6_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (256, 256, 3, 3)\n",
      "[]\n",
      "(256, 256, 3, 3)\n",
      "weight final: (256, 256, 3, 3)\n",
      "weight start: (512, 768, 1, 1)\n",
      "weight final: (512, 768, 1, 1)\n",
      "weight start: (512, 768, 1, 1)\n",
      "<class 'numpy.ndarray'> 2\n",
      "6.510857e-33\n",
      "weight final: (510, 768, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanilla/.conda/envs/testcaffe/lib/python3.5/site-packages/ipykernel_launcher.py:43: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "pruner.prune_resual(\"conv4_1_2\", \"conv4_1_1\",ind=1)\n",
    "pruner.prune_resual(\"conv4_2_1\",\"conv4_1_1b\",ind=1)\n",
    "pruner.prune_resual(\"conv4_2_2\", \"conv4_2_1\",ind=1)\n",
    "pruner.prune_resual(\"conv4_3_1\",\"conv4_1_1b\",ind=1)\n",
    "pruner.prune_resual(\"conv4_3_2\", \"conv4_3_1\",ind=1)\n",
    "pruner.prune_resual(\"conv4_4_1\",\"conv4_1_1b\",ind=1)\n",
    "pruner.prune_resual(\"conv4_4_2\", \"conv4_4_1\",ind=1)\n",
    "pruner.prune_resual(\"conv4_5_1\",\"conv4_1_1b\",ind=1)\n",
    "pruner.prune_resual(\"conv4_5_2\", \"conv4_5_1\",ind=1)\n",
    "pruner.prune_resual(\"conv4_6_1\",\"conv4_1_1b\",ind=1)\n",
    "pruner.prune_resual(\"conv4_6_2\", \"conv4_6_1\",ind=1)\n",
    "pruner.prune_concat(\"conv5_1_1\", (\"conv4_2_2\", \"conv4_4_2\", \"conv4_6_2\"))\n",
    "pruner.prune_concat(\"conv5_1_1b\", (\"conv4_2_2\", \"conv4_4_2\", \"conv4_6_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight start: (512, 512, 1, 1)\n",
      "[ 97 178]\n",
      "(510, 512, 1, 1)\n",
      "weight final: (510, 512, 1, 1)\n",
      "weight start : (512, 512, 1, 1)\n",
      "weight finally : (510, 512, 1, 1)\n",
      "weight start: (512, 512, 1, 1)\n",
      "[2 9]\n",
      "(510, 512, 1, 1)\n",
      "weight final: (510, 512, 1, 1)\n",
      "weight start : (512, 512, 1, 1)\n",
      "weight finally : (510, 512, 1, 1)\n",
      "weight start: (512, 512, 1, 1)\n",
      "[0 6]\n",
      "(510, 512, 1, 1)\n",
      "weight final: (510, 512, 1, 1)\n",
      "weight start : (512, 512, 1, 1)\n",
      "weight finally : (510, 512, 1, 1)\n",
      "weight start: (512, 512, 1, 1)\n",
      "[ 0 97]\n",
      "(510, 512, 1, 1)\n",
      "weight final: (510, 512, 1, 1)\n",
      "weight start : (512, 512, 1, 1)\n",
      "weight finally : (510, 512, 1, 1)\n",
      "weight start: (512, 512, 1, 1)\n",
      "[13 27]\n",
      "(510, 512, 1, 1)\n",
      "weight final: (510, 512, 1, 1)\n",
      "weight start : (512, 512, 1, 1)\n",
      "weight finally : (510, 512, 1, 1)\n",
      "weight start: (512, 512, 1, 1)\n",
      "[ 13 152]\n",
      "(510, 512, 1, 1)\n",
      "weight final: (510, 512, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanilla/.conda/envs/testcaffe/lib/python3.5/site-packages/ipykernel_launcher.py:43: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "pruner.prune_resual(\"conv5_1_2\",\"conv5_1_1\",ind=2)\n",
    "pruner.prune_sum(\"conv5_2_1\",(\"conv5_1_2\",\"conv5_1_1b\"))\n",
    "pruner.prune_resual(\"conv5_2_2\",\"conv5_2_1\",ind=2)\n",
    "pruner.prune_sum(\"conv5_3_1\",(\"conv5_2_2\",\"conv5_2_1\"))\n",
    "pruner.prune_resual(\"conv5_3_2\",\"conv5_3_1\",ind=2)\n",
    "pruner.prune_sum(\"conv5_4_1\",(\"conv5_3_2\",\"conv5_3_1\"))\n",
    "pruner.prune_resual(\"conv5_4_2\",\"conv5_4_1\",ind=2)\n",
    "pruner.prune_sum(\"conv5_5_1\",(\"conv5_4_2\",\"conv5_4_1\"))\n",
    "pruner.prune_resual(\"conv5_5_2\",\"conv5_5_1\",ind=2)\n",
    "pruner.prune_sum(\"conv5_6_1\",(\"conv5_5_2\",\"conv5_5_1\"))\n",
    "pruner.prune_resual(\"conv5_6_2\",\"conv5_6_1\",ind=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight start : (160, 124416)\n",
      "[0, 512, 1024, 1536]\n",
      "[0 6]\n",
      "[]\n",
      "[]\n",
      "[array([0, 6]), array([], dtype=float64), array([], dtype=float64)]\n",
      "[0. 6.]\n",
      "weight start: (160, 124416)\n",
      "weight final: (160, 124254)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanilla/.conda/envs/testcaffe/lib/python3.5/site-packages/ipykernel_launcher.py:96: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "pruner.prune_concat_fc(\"fc5_1\", [\"conv5_6_2\", \"conv5_6_1\",\"conv5_3_2\",\"conv5_5_1\"], layer=\"fc\")\n",
    "# pruner.prune_concat(\"conv6_1_1b\", (\"conv5_2_2\", \"conv5_4_2\", \"conv5_6_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fc5_1', 160),\n",
       " ('conv4_6_2', 256),\n",
       " ('conv5_5_1', 510),\n",
       " ('conv2_8', 62),\n",
       " ('conv5_3_1', 510),\n",
       " ('conv3_5_1', 128),\n",
       " ('mask', 510),\n",
       " ('conv4_3_1', 256),\n",
       " ('conv5_4_2', 510),\n",
       " ('conv4_1_2', 256),\n",
       " ('conv3_6_1', 128),\n",
       " ('conv3_4_2', 128),\n",
       " ('conv5_2_1', 510),\n",
       " ('conv1_2_1', 29),\n",
       " ('conv2_5', 64),\n",
       " ('conv3_1_1b', 128),\n",
       " ('conv4_2_2', 256),\n",
       " ('conv1_3_2', 28),\n",
       " ('conv4_2_1', 256),\n",
       " ('conv5_4_1', 510),\n",
       " ('conv4_5_1', 256),\n",
       " ('conv5_3_2', 510),\n",
       " ('conv3_3_1', 128),\n",
       " ('conv3_2_1', 128),\n",
       " ('conv4_5_2', 256),\n",
       " ('conv3_1_1', 128),\n",
       " ('conv2_4', 64),\n",
       " ('conv4_4_2', 256),\n",
       " ('conv5_6_2', 510),\n",
       " ('conv3_6_2', 128),\n",
       " ('conv4_1_1', 256),\n",
       " ('conv5_6_1', 510),\n",
       " ('conv5_1_1', 512),\n",
       " ('conv4_1_1b', 256),\n",
       " ('conv1_2_2', 31),\n",
       " ('conv3_1_2', 128),\n",
       " ('conv3_5_2', 128),\n",
       " ('conv3_4_1', 128),\n",
       " ('conv5_5_2', 510),\n",
       " ('conv2_2', 64),\n",
       " ('conv5_2_2', 510),\n",
       " ('conv5_1_2', 510),\n",
       " ('conv1_3_3', 27),\n",
       " ('conv1_1_1', 31),\n",
       " ('conv5_1_1b', 510),\n",
       " ('conv4_6_1', 256),\n",
       " ('conv4_3_2', 256),\n",
       " ('conv3_2_2', 128),\n",
       " ('conv2_7', 64),\n",
       " ('conv3_3_2', 128),\n",
       " ('conv2_1', 64),\n",
       " ('conv1_3_1', 30),\n",
       " ('conv4_4_1', 256),\n",
       " ('conv2_6', 62),\n",
       " ('conv2_3', 63)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v[0].shape[0]) for k, v in pruner.conv_data.items() if v[0] is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prototxt(pk, pro_n):  # 复制原来的prototxt,并修改修剪层的num_output,这一段代码有点绕,有空的话优化为几个单独的函数或者弄个类\n",
    "    with open(pro_n, \"r\") as p:\n",
    "        lines = p.readlines()\n",
    "    k = 0\n",
    "    with open(pro_n, \"w\") as p:\n",
    "        while k < len(lines):  # 遍历所有的lines,此处不宜用for.\n",
    "#             print(\"lines[k]:\",lines[k])\n",
    "            if 'name:' in lines[k]:\n",
    "                print(\"lines[k].split:\",lines[k].split('\"')[1])\n",
    "#                 print(pk.keys())\n",
    "                l_name = lines[k].split('\"')[1]  # 获取layer name\n",
    "                if l_name in pk.keys():  # 如果name在待修剪层中,则需要修改,下面进入一个找channel的循环块.\n",
    "                    while True:\n",
    "                        if \"num_output:\" in lines[k]:\n",
    "                            channel_n = \"    num_output: \" + str(len(pk[l_name][0])) + \"\\n\"\n",
    "                            print(channel_n)\n",
    "                            p.write(channel_n)\n",
    "                            k = k + 1\n",
    "                            break\n",
    "                        else:\n",
    "                            p.write(lines[k])\n",
    "                            k = k + 1\n",
    "                else:  # name不在待修剪层中,直接copy行\n",
    "                    p.write(lines[k])\n",
    "                    k = k + 1\n",
    " \n",
    "            else:\n",
    "                p.write(lines[k])\n",
    "                k = k + 1\n",
    "    print(\"deploy_rebirth_prune.prototxt已写好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines[k].split: TestModel\n",
      "lines[k].split: conv1_1_1\n",
      "    num_output: 31\n",
      "\n",
      "lines[k].split: conv1_1_1_relu\n",
      "lines[k].split: conv1_2_1\n",
      "    num_output: 29\n",
      "\n",
      "lines[k].split: conv1_2_1_relu\n",
      "lines[k].split: conv1_2_2\n",
      "    num_output: 31\n",
      "\n",
      "lines[k].split: conv1_2_2_relu\n",
      "lines[k].split: conv1_3_1\n",
      "    num_output: 30\n",
      "\n",
      "lines[k].split: conv1_3_1_relu\n",
      "lines[k].split: conv1_3_2\n",
      "    num_output: 28\n",
      "\n",
      "lines[k].split: conv1_3_2_relu\n",
      "lines[k].split: conv1_3_3\n",
      "    num_output: 27\n",
      "\n",
      "lines[k].split: conv1_3_3_relu\n",
      "lines[k].split: feature1\n",
      "lines[k].split: conv2_1\n",
      "    num_output: 64\n",
      "\n",
      "lines[k].split: conv2_1_relu\n",
      "lines[k].split: conv2_2\n",
      "    num_output: 64\n",
      "\n",
      "lines[k].split: conv2_2_relu\n",
      "lines[k].split: conv2_3\n",
      "    num_output: 63\n",
      "\n",
      "lines[k].split: conv2_3_relu\n",
      "lines[k].split: conv2_4\n",
      "    num_output: 64\n",
      "\n",
      "lines[k].split: conv2_4_relu\n",
      "lines[k].split: conv2_5\n",
      "    num_output: 64\n",
      "\n",
      "lines[k].split: conv2_5_relu\n",
      "lines[k].split: conv2_6\n",
      "    num_output: 62\n",
      "\n",
      "lines[k].split: conv2_6_relu\n",
      "lines[k].split: conv2_7\n",
      "    num_output: 64\n",
      "\n",
      "lines[k].split: conv2_7_relu\n",
      "lines[k].split: conv2_8\n",
      "    num_output: 62\n",
      "\n",
      "lines[k].split: conv2_8_relu\n",
      "lines[k].split: feature2\n",
      "lines[k].split: conv3_1_1b\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: conv3_1_1\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: relu_conv3_1_1\n",
      "lines[k].split: conv3_1_2\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: res_conv3_1_2\n",
      "lines[k].split: relu_res_conv3_1_2\n",
      "lines[k].split: conv3_2_1\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: relu_conv3_2_1\n",
      "lines[k].split: conv3_2_2\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: res_conv3_2_2\n",
      "lines[k].split: relu_res_conv3_2_2\n",
      "lines[k].split: conv3_3_1\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: relu_conv3_3_1\n",
      "lines[k].split: conv3_3_2\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: res_conv3_3_2\n",
      "lines[k].split: relu_res_conv3_3_2\n",
      "lines[k].split: conv3_4_1\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: relu_conv3_4_1\n",
      "lines[k].split: conv3_4_2\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: res_conv3_4_2\n",
      "lines[k].split: relu_res_conv3_4_2\n",
      "lines[k].split: conv3_5_1\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: relu_conv3_5_1\n",
      "lines[k].split: conv3_5_2\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: res_conv3_5_2\n",
      "lines[k].split: relu_res_conv3_5_2\n",
      "lines[k].split: conv3_6_1\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: relu_conv3_6_1\n",
      "lines[k].split: conv3_6_2\n",
      "    num_output: 128\n",
      "\n",
      "lines[k].split: res_conv3_6_2\n",
      "lines[k].split: relu_res_conv3_6_2\n",
      "lines[k].split: feature3\n",
      "lines[k].split: conv4_1_1b\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: conv4_1_1\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: relu_conv4_1_1\n",
      "lines[k].split: conv4_1_2\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: res_conv4_1_2\n",
      "lines[k].split: relu_res_conv4_1_2\n",
      "lines[k].split: conv4_2_1\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: relu_conv4_2_1\n",
      "lines[k].split: conv4_2_2\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: res_conv4_2_2\n",
      "lines[k].split: relu_res_conv4_2_2\n",
      "lines[k].split: conv4_3_1\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: relu_conv4_3_1\n",
      "lines[k].split: conv4_3_2\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: res_conv4_3_2\n",
      "lines[k].split: relu_res_conv4_3_2\n",
      "lines[k].split: conv4_4_1\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: relu_conv4_4_1\n",
      "lines[k].split: conv4_4_2\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: res_conv4_4_2\n",
      "lines[k].split: relu_res_conv4_4_2\n",
      "lines[k].split: conv4_5_1\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: relu_conv4_5_1\n",
      "lines[k].split: conv4_5_2\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: res_conv4_5_2\n",
      "lines[k].split: relu_res_conv4_5_2\n",
      "lines[k].split: conv4_6_1\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: relu_conv4_6_1\n",
      "lines[k].split: conv4_6_2\n",
      "    num_output: 256\n",
      "\n",
      "lines[k].split: res_conv4_6_2\n",
      "lines[k].split: relu_res_conv4_6_2\n",
      "lines[k].split: feature4\n",
      "lines[k].split: conv5_1_1b\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: conv5_1_1\n",
      "    num_output: 512\n",
      "\n",
      "lines[k].split: relu_conv5_1_1\n",
      "lines[k].split: conv5_1_2\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: res_conv5_1_2\n",
      "lines[k].split: relu_res_conv5_1_2\n",
      "lines[k].split: conv5_2_1\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: relu_conv5_2_1\n",
      "lines[k].split: conv5_2_2\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: res_conv5_2_2\n",
      "lines[k].split: relu_res_conv5_2_2\n",
      "lines[k].split: conv5_3_1\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: relu_conv5_3_1\n",
      "lines[k].split: conv5_3_2\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: res_conv5_3_2\n",
      "lines[k].split: relu_res_conv5_3_2\n",
      "lines[k].split: conv5_4_1\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: relu_conv5_4_1\n",
      "lines[k].split: conv5_4_2\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: res_conv5_4_2\n",
      "lines[k].split: relu_res_conv5_4_2\n",
      "lines[k].split: conv5_5_1\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: relu_conv5_5_1\n",
      "lines[k].split: conv5_5_2\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: res_conv5_5_2\n",
      "lines[k].split: relu_res_conv5_5_2\n",
      "lines[k].split: conv5_6_1\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: relu_conv5_6_1\n",
      "lines[k].split: conv5_6_2\n",
      "    num_output: 510\n",
      "\n",
      "lines[k].split: res_conv5_6_2\n",
      "lines[k].split: relu_res_conv5_6_2\n",
      "lines[k].split: feature5\n",
      "lines[k].split: fc5_1\n",
      "    num_output: 160\n",
      "\n",
      "lines[k].split: fc5_\n",
      "deploy_rebirth_prune.prototxt已写好\n"
     ]
    }
   ],
   "source": [
    "pro_n = root + \"TestModel.prototxt\"\n",
    "shutil.copyfile(prototxt, pro_n)\n",
    "get_prototxt(pruner.conv_data, pro_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_1_1\n",
      "(31, 3, 3, 3)\n",
      "conv1_2_1\n",
      "(29, 3, 3, 3)\n",
      "conv1_2_2\n",
      "(31, 29, 3, 3)\n",
      "conv1_3_1\n",
      "(30, 3, 3, 3)\n",
      "conv1_3_2\n",
      "(28, 30, 3, 3)\n",
      "conv1_3_3\n",
      "(27, 28, 3, 3)\n",
      "conv2_1\n",
      "(64, 89, 3, 3)\n",
      "conv2_2\n",
      "(64, 64, 3, 3)\n",
      "conv2_3\n",
      "(63, 64, 3, 3)\n",
      "conv2_4\n",
      "(64, 63, 3, 3)\n",
      "conv2_5\n",
      "(64, 64, 3, 3)\n",
      "conv2_6\n",
      "(62, 64, 3, 3)\n",
      "conv2_7\n",
      "(64, 62, 3, 3)\n",
      "conv2_8\n",
      "(62, 64, 3, 3)\n",
      "conv3_1_1b\n",
      "(128, 252, 1, 1)\n",
      "conv3_1_1\n",
      "(128, 252, 3, 3)\n",
      "conv3_1_2\n",
      "(128, 128, 3, 3)\n",
      "conv3_2_1\n",
      "(128, 128, 3, 3)\n",
      "conv3_2_2\n",
      "(128, 128, 3, 3)\n",
      "conv3_3_1\n",
      "(128, 128, 3, 3)\n",
      "conv3_3_2\n",
      "(128, 128, 3, 3)\n",
      "conv3_4_1\n",
      "(128, 128, 3, 3)\n",
      "conv3_4_2\n",
      "(128, 128, 3, 3)\n",
      "conv3_5_1\n",
      "(128, 128, 3, 3)\n",
      "conv3_5_2\n",
      "(128, 128, 3, 3)\n",
      "conv3_6_1\n",
      "(128, 128, 3, 3)\n",
      "conv3_6_2\n",
      "(128, 128, 3, 3)\n",
      "conv4_1_1b\n",
      "(256, 384, 1, 1)\n",
      "conv4_1_1\n",
      "(256, 384, 3, 3)\n",
      "conv4_1_2\n",
      "(256, 256, 3, 3)\n",
      "conv4_2_1\n",
      "(256, 256, 3, 3)\n",
      "conv4_2_2\n",
      "(256, 256, 3, 3)\n",
      "conv4_3_1\n",
      "(256, 256, 3, 3)\n",
      "conv4_3_2\n",
      "(256, 256, 3, 3)\n",
      "conv4_4_1\n",
      "(256, 256, 3, 3)\n",
      "conv4_4_2\n",
      "(256, 256, 3, 3)\n",
      "conv4_5_1\n",
      "(256, 256, 3, 3)\n",
      "conv4_5_2\n",
      "(256, 256, 3, 3)\n",
      "conv4_6_1\n",
      "(256, 256, 3, 3)\n",
      "conv4_6_2\n",
      "(256, 256, 3, 3)\n",
      "conv5_1_1b\n",
      "(510, 768, 1, 1)\n",
      "conv5_1_1\n",
      "(512, 768, 1, 1)\n",
      "conv5_1_2\n",
      "(510, 512, 1, 1)\n",
      "conv5_2_1\n",
      "(510, 512, 1, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (510,512,1,1) into shape (510,510,1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-0ec9c18e03c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You should modify the number of channels in new prototxt before save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpruner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpro_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/media/vanilla/Fun/zhongxing/Test/TestModel.caffemodel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-f7586625eef0>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, new_model, output_weights)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (510,512,1,1) into shape (510,510,1,1)"
     ]
    }
   ],
   "source": [
    "# You should modify the number of channels in new prototxt before save\n",
    "pruner.save(pro_n, \"/media/vanilla/Fun/zhongxing/Test/TestModel.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caffe",
   "language": "python",
   "name": "testcaffe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
